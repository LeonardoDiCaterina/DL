{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# test utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from .preprocessing_config import DATA_DIR,DEST_DIR,CSV_PATH\n",
    "from .data_loading import load_data, split_folds_to_train_val\n",
    "from .augmentation import save_to_split_to_directory\n",
    "DEST_DIR = 'data/test_functional'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# chang edirectory with absolute path\n",
    "DL_path = os.path.abspath('/Users/leonardodicaterina/Desktop/NovaIMS/DL')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "csv_file_path = os.path.join(DL_path, CSV_PATH)\n",
    "df = pd.read_csv(csv_file_path)\n",
    "df_head = df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-20 13:20:44,006 - augmentation - INFO - Starting oversampling and saving process\n",
      "2025-04-20 13:20:44,006 - augmentation - INFO - origin_root: data/rare_species 1 --> dest_root: data/test_functional\n",
      "2025-04-20 13:20:44,008 - data_utils - INFO - Calculating number of oversampling copies per class\n",
      "2025-04-20 13:20:44,009 - data_utils - INFO - Analyzing class proportions\n",
      "/Users/leonardodicaterina/Desktop/NovaIMS/DL/data_preprocessing/augmentation.py:33: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['copies'] = aligned_copies.values\n",
      "  0%|          | 0/5 [00:00<?, ?it/s]2025-04-20 13:20:44,025 - augmentation - WARNING - Source file does not exist: data/rare_species 1/mollusca_unionidae/12853737_449393_eol-full-size-copy.jpg\n",
      "2025-04-20 13:20:44,025 - augmentation - WARNING - Source file does not exist: data/rare_species 1/chordata_geoemydidae/20969394_793083_eol-full-size-copy.jpg\n",
      "2025-04-20 13:20:44,026 - augmentation - WARNING - Source file does not exist: data/rare_species 1/chordata_cryptobranchidae/28895411_319982_eol-full-size-copy.jpg\n",
      "2025-04-20 13:20:44,026 - augmentation - WARNING - Source file does not exist: data/rare_species 1/chordata_turdidae/29658536_45510188_eol-full-size-copy.jpg\n",
      "2025-04-20 13:20:44,026 - augmentation - WARNING - Source file does not exist: data/rare_species 1/chordata_indriidae/21252576_7250886_eol-full-size-copy.jpg\n",
      "100%|██████████| 5/5 [00:00<00:00, 2196.20it/s]\n",
      "2025-04-20 13:20:44,026 - augmentation - INFO - Oversampling and saving process completed\n"
     ]
    }
   ],
   "source": [
    "save_to_split_to_directory(df_head, DATA_DIR, DEST_DIR, oversample=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__init__.py              data_utils.py            test_preprocessing.ipynb\n",
      "\u001b[34m__pycache__\u001b[m\u001b[m              logger.py                test_splitting.py\n",
      "augmentation.py          main.py                  \u001b[34mtests\u001b[m\u001b[m\n",
      "config.py                splitting.py             \u001b[34mutils\u001b[m\u001b[m\n",
      "data_loading.py          test_data_utils.py\n"
     ]
    }
   ],
   "source": [
    "! ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-20 13:20:44,585 - data_loading - INFO - Loading data from data/rearranged\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/leonardodicaterina/Desktop/NovaIMS/DL\n",
      "Found 2397 files belonging to 202 classes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-20 13:20:44,763 - data_loading - INFO - Loaded test dataset with 75 batches\n",
      "2025-04-20 13:20:44,763 - data_loading - INFO - Test dataset shape: (TensorSpec(shape=(None, 256, 256, 3), dtype=tf.float32, name=None), TensorSpec(shape=(None, 202), dtype=tf.float32, name=None))\n",
      "Loading folds:   0%|          | 0/5 [00:00<?, ?it/s]2025-04-20 13:20:44,764 - data_loading - INFO - Loading fold 0 from data/rearranged/fold_0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1918 files belonging to 202 classes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-20 13:20:44,858 - data_loading - INFO - Loading fold 1 from data/rearranged/fold_1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1917 files belonging to 202 classes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading folds:  40%|████      | 2/5 [00:00<00:00,  4.23it/s]2025-04-20 13:20:45,246 - data_loading - INFO - Loading fold 2 from data/rearranged/fold_2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1917 files belonging to 202 classes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading folds:  60%|██████    | 3/5 [00:00<00:00,  5.33it/s]2025-04-20 13:20:45,357 - data_loading - INFO - Loading fold 3 from data/rearranged/fold_3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1917 files belonging to 202 classes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-20 13:20:45,440 - data_loading - INFO - Loading fold 4 from data/rearranged/fold_4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1917 files belonging to 202 classes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading folds: 100%|██████████| 5/5 [00:00<00:00,  6.61it/s]\n",
      "2025-04-20 13:20:45,522 - data_loading - INFO - Loaded 5 folds\n"
     ]
    }
   ],
   "source": [
    "os.chdir(DL_path)\n",
    "# print current working directory\n",
    "print(os.getcwd())\n",
    "train_data, tes_data = load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-20 13:20:48,136 - data_loading - INFO - Validation dataset shape: (TensorSpec(shape=(None, 256, 256, 3), dtype=tf.float32, name=None), TensorSpec(shape=(None, 202), dtype=tf.float32, name=None))\n",
      "2025-04-20 13:20:48,137 - data_loading - INFO - Validation dataset length: 60\n",
      "2025-04-20 13:20:48,145 - data_loading - INFO - Training dataset shape: (TensorSpec(shape=(None, 256, 256, 3), dtype=tf.float32, name=None), TensorSpec(shape=(None, 202), dtype=tf.float32, name=None))\n",
      "2025-04-20 13:20:48,145 - data_loading - INFO - Training dataset length: 240\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(<_ConcatenateDataset element_spec=(TensorSpec(shape=(None, 256, 256, 3), dtype=tf.float32, name=None), TensorSpec(shape=(None, 202), dtype=tf.float32, name=None))>,\n",
       " <_PrefetchDataset element_spec=(TensorSpec(shape=(None, 256, 256, 3), dtype=tf.float32, name=None), TensorSpec(shape=(None, 202), dtype=tf.float32, name=None))>)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "split_folds_to_train_val(train_data, 0)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DL_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
